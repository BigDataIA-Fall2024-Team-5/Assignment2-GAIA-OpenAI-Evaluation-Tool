# Assignment1-GAIA-OpenAI-Evaluation-Tool

Application Link: https://team5-assignment1.streamlit.app/ 
Code Lab Link: https://codelabs-preview.appspot.com/?file_id=1a1lWq_iTi-cp2h0ZCZ2yJs9ST9suEgrhw78o4ldVr0M#0 
Presentation Video Link: https://drive.google.com/file/d/1HdkIqzupZM6o4eZYRvcK_zLyv5mOZoi2/view?usp=drive_link 

## OpenAI Evaluation App

This repository contains an application that evaluates a dataset of questions using OpenAIâ€™s ChatGPT model. It processes data from the GAIA dataset, including associated files (e.g., text, CSV, Excel, Word, PDF, and PowerPoint), uploads supported files to AWS S3 for secure storage, and stores the evaluation results in Azure SQL. The app offers a user-friendly Streamlit interface to visualize the results through **Matplotlib**, making it easier to analyze ChatGPT's performance.

## Table of Contents

1. [Key Features](#key-features)
2. [Project Structure](#project-structure)
3. [Understanding `newapp.py`](#understanding-newapppy)
4. [Installation](#installation)
5. [Usage](#usage)
6. [License](#license)

## Key Features

- **GAIA Dataset Integration**: Loads a set of questions from the GAIA dataset using Hugging Face. Each question includes a "final answer" that is compared against the answer generated by ChatGPT.
- **File Retrieval and Upload**: During the initial data push, any files associated with the questions are cloned from the GAIA repository, uploaded to AWS S3, and their paths are updated in the Azure SQL database.
- **ChatGPT Evaluation**: For each question, the app generates an answer using the ChatGPT model. If a question has an associated file (e.g., text, CSV, Excel, Word, PDF, or PowerPoint), the file is downloaded from AWS S3, preprocessed, and included in the ChatGPT request. The modelâ€™s response is then compared to the final answer provided in the GAIA dataset. Unsupported file types, such as audio, images, and zip files, are flagged and excluded from the request.
- **Azure SQL Database**: Data is stored in Azure SQL, including the updated file paths from AWS S3, and the evaluation results are stored as well.
- **Admin Management**: The app includes admin features that allow dataset management, user promotion, and user deletion through a dedicated admin dashboard.
- **Visualization**: The app generates visualizations of ChatGPT's performance using **Matplotlib** to help interpret the results.

## Project Structure

ðŸ“¦ openai-evaluation-streamlit  
 â”£ ðŸ“‚ scripts  
 â”ƒ â”£ ðŸ“‚ api_utils         # Scripts for handling API interactions (AWS, OpenAI, Azure SQL)  
 â”ƒ â”£ ðŸ“‚ data_handling     # Scripts for handling data (cloning, processing, etc.)  
 â”ƒ â”£ ðŸ“œ main.py           # Main orchestration script  
 â”ƒ â”£ ðŸ“œ setup_database.py  # Script for setting up the Azure SQL database  
 â”£ ðŸ“‚ streamlit_pages      # Pages for the Streamlit web interface  
 â”£ ðŸ“œ newapp.py            # Main entry point for the evaluation app  
 â”£ ðŸ“œ .env                 # Environment variable configuration  
 â”£ ðŸ“œ .gitignore           # File to exclude unnecessary files from Git  
 â”£ ðŸ“œ poetry.lock          # Poetry lock file for dependencies  
 â”£ ðŸ“œ pyproject.toml       # Poetry project configuration  
 â”£ ðŸ“œ LICENSE              # MIT License file  
 â”£ ðŸ“œ README.md            # Main README file

## Understanding `newapp.py`

The `newapp.py` script is the main entry point of the Streamlit application that manages the app's navigation and interaction between different pages. Here's what it does:

1. **Page Navigation**:
   - The app initializes with a **landing page**, where the user is introduced to the tool.
   - Users can navigate to the **main evaluation page**, where they can explore questions and send them to ChatGPT for evaluation.
   - The **explore questions** page allows users to select individual questions from the GAIA dataset, view related final answers, and evaluate ChatGPT's responses.
   - The **summary page** provides an overview of all results, visualized using **Matplotlib**.
   - The **admin dashboard** provides admins the ability to manage datasets and users. Admins can delete users, promote users to admin, and trigger dataset processing.

2. **ChatGPT Evaluation**:
   - In the initial setup, the GAIA dataset is processed, files are uploaded to AWS S3, and file paths are updated in Azure SQL.
   - When a question with an associated file is selected for evaluation, the file is downloaded from AWS S3, preprocessed, and included in the request to ChatGPT.
   - ChatGPTâ€™s response is compared to the final answer, and the result (correct/incorrect) is stored in Azure SQL.

3. **Result Storage and Visualization**:
   - The results of the evaluation are stored in **Azure SQL**.
   - Users can view the results as bar charts using **Matplotlib**, which provides insight into how accurately ChatGPT answered the questions.

## Installation

To get the project running on your local machine, follow these steps:

### Prerequisites

Ensure you have the following installed:
- Python 3.x
- Poetry (for dependency management)
- AWS account (for S3 storage)
- Azure SQL database (for data management)
- OpenAI API key (for accessing OpenAI models)
- Hugging Face account and token

### Steps

1. **Clone the repository** and install dependencies using Poetry:

   git clone https://github.com/your-username/openai-evaluation-streamlit.git  
   cd openai-evaluation-streamlit  
   poetry install

2. **Set up environment variables**:

   Create a `.env` file in the root of the project and add your credentials for AWS, Azure SQL, OpenAI, Hugging Face, and S3 bucket:

   HF_TOKEN='your-hugging-face-token'  
   OPENAI_API_KEY='your-openai-api-key'  
   AWS_ACCESS_KEY='your-aws-access-key'  
   AWS_SECRET_KEY='your-aws-secret-key'  
   S3_BUCKET_NAME='your-s3-bucket-name'  
   GAIA_REPO_URL='https://huggingface.co/datasets/gaia-benchmark/GAIA'  
   AZURE_SQL_SERVER='your-azure-sql-server'  
   AZURE_SQL_DATABASE='your-azure-sql-database'  
   AZURE_SQL_TABLE='your-azure-sql-table'  
   AZURE_SQL_USER='your-azure-sql-username'  
   AZURE_SQL_PASSWORD='your-azure-sql-password'  

3. **Run the application**:

   Start the Streamlit app using the following command:

   streamlit run newapp.py


## Usage

Once the application is set up and the environment variables are configured, follow these steps to use the app:

1. **Run the Streamlit app**:

   You can start the Streamlit app using the following command:

   streamlit run newapp.py

2. **Explore the web interface**:

   Once the app is running, navigate to the URL displayed in the terminal (usually http://localhost:8501) to interact with the web interface. The app provides the following features:

   - **Initial Data Push**: The GAIA dataset and associated files are cloned, files are uploaded to AWS S3, and the updated file paths are stored in Azure SQL.
   - **Question Evaluation**: For each question, ChatGPT generates a response, which is compared to the final answer. If a question has an associated file, it is downloaded from AWS S3, preprocessed, and included in the ChatGPT evaluation.
   - **Result Visualization**: The app displays results using Matplotlib for easy analysis and interpretation.

3. **Data Processing**:

   - During the initial push, the dataset and any associated files are cloned, files are uploaded to AWS S3, and the file paths are updated in Azure SQL.
   - Files associated with questions are downloaded and preprocessed during evaluation, and the results are stored in Azure SQL.

## License

This project is licensed under the MIT License. For more details, please refer to the LICENSE file.


